{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T15:52:31.245079Z","iopub.status.busy":"2024-04-06T15:52:31.244557Z","iopub.status.idle":"2024-04-06T15:52:31.251661Z","shell.execute_reply":"2024-04-06T15:52:31.250684Z","shell.execute_reply.started":"2024-04-06T15:52:31.245046Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["d:\\Programs\\Programming\\BSUIR\\NLIIS\\LW6\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["from torch import cuda, bfloat16\n","import torch\n","import transformers\n","from transformers import AutoTokenizer\n","from time import time\n","#import chromadb\n","#from chromadb.config import Settings\n","from langchain.llms import HuggingFacePipeline\n","from langchain.document_loaders import TextLoader,PyPDFLoader\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain.embeddings import HuggingFaceEmbeddings\n","from langchain.chains import RetrievalQA\n","from langchain.vectorstores import Chroma\n","from langchain_core.output_parsers import StrOutputParser"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.87s/it]\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"name":"stdout","output_type":"stream","text":["Prepare model, tokenizer: 14.064 sec.\n"]}],"source":["model_id = 'model/Qwen1.5-4B-Chat/'\n","\n","device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n","\n","# set quantization configuration to load large model with less GPU memory\n","# this requires the `bitsandbytes` library\n","# bnb_config = transformers.BitsAndBytesConfig(\n","#     load_in_8bit=True,  # Load model weights in 8-bit format\n","#     bnb_8bit_quant_type='nf8',  # Use nf8 quantization scheme for 8-bit\n","#     bnb_8bit_use_double_quant=True,  # Use double quantization for 8-bit\n","#     bnb_8bit_compute_dtype='bfloat16'  # Compute using bfloat16 for 8-bit quantization\n","# )\n","\n","bnb_config = transformers.BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_quant_type='nf4',\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_compute_dtype=bfloat16\n",")\n","\n","time_1 = time()\n","model_config = transformers.AutoConfig.from_pretrained(\n","    model_id,\n",")\n","model = transformers.AutoModelForCausalLM.from_pretrained(\n","    model_id,\n","    trust_remote_code=True,\n","    config=model_config,\n","    quantization_config=bnb_config,\n","    device_map='auto',\n",")\n","tokenizer = AutoTokenizer.from_pretrained(model_id)\n","time_2 = time()\n","print(f\"Prepare model, tokenizer: {round(time_2-time_1, 3)} sec.\")"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T15:53:34.265678Z","iopub.status.busy":"2024-04-06T15:53:34.265197Z","iopub.status.idle":"2024-04-06T15:59:52.561900Z","shell.execute_reply":"2024-04-06T15:59:52.561072Z","shell.execute_reply.started":"2024-04-06T15:53:34.265643Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["The model 'Qwen2ForCausalLM' is not supported for question-answering. Supported models are ['AlbertForQuestionAnswering', 'BartForQuestionAnswering', 'BertForQuestionAnswering', 'BigBirdForQuestionAnswering', 'BigBirdPegasusForQuestionAnswering', 'BloomForQuestionAnswering', 'CamembertForQuestionAnswering', 'CanineForQuestionAnswering', 'ConvBertForQuestionAnswering', 'Data2VecTextForQuestionAnswering', 'DebertaForQuestionAnswering', 'DebertaV2ForQuestionAnswering', 'DistilBertForQuestionAnswering', 'ElectraForQuestionAnswering', 'ErnieForQuestionAnswering', 'ErnieMForQuestionAnswering', 'FalconForQuestionAnswering', 'FlaubertForQuestionAnsweringSimple', 'FNetForQuestionAnswering', 'FunnelForQuestionAnswering', 'GPT2ForQuestionAnswering', 'GPTNeoForQuestionAnswering', 'GPTNeoXForQuestionAnswering', 'GPTJForQuestionAnswering', 'IBertForQuestionAnswering', 'LayoutLMv2ForQuestionAnswering', 'LayoutLMv3ForQuestionAnswering', 'LEDForQuestionAnswering', 'LiltForQuestionAnswering', 'LlamaForQuestionAnswering', 'LongformerForQuestionAnswering', 'LukeForQuestionAnswering', 'LxmertForQuestionAnswering', 'MarkupLMForQuestionAnswering', 'MBartForQuestionAnswering', 'MegaForQuestionAnswering', 'MegatronBertForQuestionAnswering', 'MobileBertForQuestionAnswering', 'MPNetForQuestionAnswering', 'MptForQuestionAnswering', 'MraForQuestionAnswering', 'MT5ForQuestionAnswering', 'MvpForQuestionAnswering', 'NezhaForQuestionAnswering', 'NystromformerForQuestionAnswering', 'OPTForQuestionAnswering', 'QDQBertForQuestionAnswering', 'ReformerForQuestionAnswering', 'RemBertForQuestionAnswering', 'RobertaForQuestionAnswering', 'RobertaPreLayerNormForQuestionAnswering', 'RoCBertForQuestionAnswering', 'RoFormerForQuestionAnswering', 'SplinterForQuestionAnswering', 'SqueezeBertForQuestionAnswering', 'T5ForQuestionAnswering', 'UMT5ForQuestionAnswering', 'XLMForQuestionAnsweringSimple', 'XLMRobertaForQuestionAnswering', 'XLMRobertaXLForQuestionAnswering', 'XLNetForQuestionAnsweringSimple', 'XmodForQuestionAnswering', 'YosoForQuestionAnswering'].\n"]}],"source":["query_pipeline = transformers.pipeline(\n","        \"text-generation\",\n","        model=model,\n","        tokenizer=tokenizer,\n","        torch_dtype=torch.float16,\n","        device_map=\"auto\",\n","        # temperature=0.7,\n","        # max_new_tokens=200,\n","        # trust_remote_code=True,\n",")"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["llm = HuggingFacePipeline(pipeline=query_pipeline)"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n"]}],"source":["from langchain.prompts import PromptTemplate\n","template = \"\"\"Question: {question}\\nAnswer: \"\"\"\n","prompt = PromptTemplate.from_template(template)\n","\n","chain = prompt | llm\n","\n","question = \"What it is a human heart ?\"\n","\n","print(chain.invoke({\"question\": question}))"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# loader = PyPDFLoader('text_corpus/Bergman_s_comprehensive_encyclopedia_of_human_anatomic_variation_Bergman_1_ed_2016.pdf')\n","# documents = loader.load()\n","\n","# text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=20)\n","# all_splits = text_splitter.split_documents(documents)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# model_name = \"sentence-transformers/all-mpnet-base-v2\"\n","# model_kwargs = {\"device\": \"cuda\"}\n","\n","# embeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# len(all_splits)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# vectordb = Chroma.from_documents(documents=all_splits[:100], embedding=embeddings, persist_directory=\"chroma_db\")"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":["True"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.is_available()"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T16:00:21.829504Z","iopub.status.busy":"2024-04-06T16:00:21.828753Z","iopub.status.idle":"2024-04-06T16:00:21.834310Z","shell.execute_reply":"2024-04-06T16:00:21.833280Z","shell.execute_reply.started":"2024-04-06T16:00:21.829459Z"},"trusted":true},"outputs":[],"source":["# retriever = vectordb.as_retriever()"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# rag_chain = (\n","#     {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n","#     | prompt\n","#     | llm\n","#     | StrOutputParser()\n","# )"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["# qa = RetrievalQA.from_chain_type(\n","#     llm=llm, \n","#     chain_type=\"stuff\", \n","#     retriever=retriever, \n","#     verbose=True\n","# )"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["# torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["# result = qa.run('How can human anatomic variation can be defined? Keep it under 10 words')\n","# result"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4742878,"sourceId":8043987,"sourceType":"datasetVersion"},{"isSourceIdPinned":true,"modelInstanceId":3093,"sourceId":4298,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30674,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
